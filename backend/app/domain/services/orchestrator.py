"""Core orchestration for turning questions into ClickHouse SQL answers."""

from __future__ import annotations

import logging
import time
from typing import Any

from ...infra.cache.client import RedisCache
from ...infra.cache.keys import fingerprint_key, question_key
from ...infra.clickhouse.client import ClickHouseClient
from ...infra.config import Settings, get_settings
from ...infra.sql.normalizer import normalize_sql_for_clickhouse
from ...infra.llm.base import LLMClientProtocol
from ...infra.llm.factory import get_llm_client
from .prompt_builder import render_sql_prompt
from .sql_builder import clean_sql_output
from .summarizer import Summarizer

logger = logging.getLogger(__name__)


class QueryOrchestrator:
    """Coordinates prompt generation, LLM calls, ClickHouse querying, and caching."""

    def __init__(
        self,
        *,
        settings: Settings | None = None,
        llm_client: LLMClientProtocol | None = None,
        clickhouse: ClickHouseClient,
        cache: RedisCache,
    ) -> None:
        self._settings = settings or get_settings()
        self._llm = llm_client or get_llm_client(self._settings)
        self._clickhouse = clickhouse
        self._cache = cache
        self._summarizer = Summarizer(self._llm)

    async def run(self, *, question: str, user_id: str | None) -> dict[str, Any]:
        question = question.strip()
        if not question:
            raise ValueError("Question cannot be empty")

        start_time = time.perf_counter()
        cached = await self._try_read_cache(question)
        if cached:
            logger.info("cache_hit question=%s", question[:80])
            return cached

        sql_prompt = render_sql_prompt(question, [f"Q: {question}"])
        sql_raw = await self._llm.generate_text(sql_prompt)
        sql_clean = clean_sql_output(sql_raw)
        if not sql_clean:
            logger.error("empty_sql_cleaned question=%s", question)
            raise ValueError("No valid SQL generated by LLM")

        sql = normalize_sql_for_clickhouse(sql_clean)
        rows = await self._clickhouse.query(sql)

        summary = await self._summarizer.summarise(question, sql, rows)

        payload = {"sql": sql, "data": rows, "summary": summary}
        await self._store_cache(question, sql, payload)

        elapsed = time.perf_counter() - start_time
        logger.info("query_latency_seconds=%.3f", elapsed)
        return payload

    async def _try_read_cache(self, question: str) -> dict[str, Any] | None:
        question_mapping = await self._cache.read(question_key(question))
        if not question_mapping:
            return None
        fp_key = question_mapping.get("fingerprint")
        if not isinstance(fp_key, str):
            return None
        return await self._cache.read(fp_key)

    async def _store_cache(self, question: str, sql: str, payload: dict[str, Any]) -> None:
        fp_key = fingerprint_key(question, sql)
        await self._cache.write(fp_key, payload)
        await self._cache.write(question_key(question), {"fingerprint": fp_key})
